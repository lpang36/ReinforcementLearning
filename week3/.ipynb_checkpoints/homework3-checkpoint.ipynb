{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#XVFB will be launched if you run on a server\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY=:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Q-learning in the wild\n",
    "\n",
    "Here we use the qlearning agent from before on taxi env from openai gym.\n",
    "You will need to insert a few agent functions here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make(\"Taxi-v2\")\n",
    "\n",
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlearning import QLearningAgent\n",
    "\n",
    "agent = QLearningAgent(alpha=0.5,epsilon=0.25,discount=0.99,\n",
    "                       getLegalActions = lambda s: range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_and_train(env,agent,t_max=10**4):\n",
    "    \"\"\"This function should \n",
    "    - run a full game, actions given by agent.getAction(s)\n",
    "    - train agent using agent.update(...) whenever possible\n",
    "    - return total reward\"\"\"\n",
    "    total_reward = 0.0\n",
    "    s = env.reset()\n",
    "    \n",
    "    for t in range(t_max):\n",
    "        a = agent.getAction(s)\n",
    "        \n",
    "        next_s,r,done,_ = env.step(a)\n",
    "        \n",
    "        agent.update(s,a,next_s,r)\n",
    "        \n",
    "        s = next_s\n",
    "        total_reward +=r\n",
    "        if done:break\n",
    "        \n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward 4.46\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSrmcBgKllHK5/w868rclPed03gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe9b868fa50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rewards = []\n",
    "for i in range(1000):\n",
    "    rewards.append(play_and_train(env,agent))    \n",
    "    agent.epsilon *= 0.999\n",
    "    if i %100 ==0:\n",
    "        clear_output(True)\n",
    "        print \"mean reward\",np.mean(rewards[-100:])\n",
    "        plt.plot(rewards)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 reducing epsilon\n",
    "\n",
    "Try decreasing agent epsilon over time to make him reach positive score.\n",
    "\n",
    "The straightforward way to do so is to reduce epsilon every N games:\n",
    "* either multiply agent.epsilon by a number less than 1 (e.g. 0.99)\n",
    "* or substract a small value until it reaches 0\n",
    "\n",
    "You can, of-course, devise other strategies.\n",
    "\n",
    "__The goal is to reach positive reward!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SARSA (2 pts)\n",
    "\n",
    "```<Please go to sarsa.py and implement the missing lines in update method>```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sarsa import SarsaAgent\n",
    "agent = SarsaAgent(alpha=0.1,epsilon=0.1,discount=0.99,\n",
    "                       getLegalActions = lambda s: range(n_actions))\n",
    "#Note that SARSA will likely need smaller learning rate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_and_train_sarsa(env,agent,t_max=10**4):\n",
    "    \"\"\"This function should \n",
    "    - run a full game, actions given by agent.getAction(s)\n",
    "    - train agent using agent.update(...) whenever possible\n",
    "    - return total reward\"\"\"\n",
    "    total_reward = 0.0\n",
    "    s = env.reset()\n",
    "    \n",
    "    for t in range(t_max):\n",
    "        a = agent.getAction(s)\n",
    "        \n",
    "        next_s,r,done,_ = env.step(a)\n",
    "        \n",
    "        agent.update(s,a,next_s,agent.getAction(next_s),r)\n",
    "        \n",
    "        s = next_s\n",
    "        total_reward +=r\n",
    "        if done:break\n",
    "        \n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "update() takes exactly 5 arguments (6 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-fd49da2d843e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplay_and_train_sarsa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-24a62042be71>\u001b[0m in \u001b[0;36mplay_and_train_sarsa\u001b[0;34m(env, agent, t_max)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mnext_s\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_s\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: update() takes exactly 5 arguments (6 given)"
     ]
    }
   ],
   "source": [
    "rewards = []\n",
    "for i in range(1000):\n",
    "    rewards.append(play_and_train_sarsa(env,agent))    \n",
    "    if i %100 ==0:\n",
    "        clear_output(True)\n",
    "        print \"mean reward\",np.mean(rewards[-100:])\n",
    "        plt.plot(rewards)\n",
    "        plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Continuous state space (2 pts)\n",
    "\n",
    "Use agent to train on CartPole-v0\n",
    "\n",
    "This environment has a continuous number of states, so you will have to group them into bins somehow.\n",
    "\n",
    "The simplest way is to use `round(x,n_digits)` (or numpy round) to round real number to a given amount of digits.\n",
    "\n",
    "The tricky part is to get the n_digits right for each state to train effectively.\n",
    "\n",
    "Note that you don't need to convert state to integers, but to __tuples__ of any kind of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "print(\"first state:%s\"%(env.reset()))\n",
    "plt.imshow(env.render('rgb_array'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play a few games\n",
    "\n",
    "We need to estimate observation distributions. To do so, we'll play a few games and record all states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = []\n",
    "for _ in range(1000):\n",
    "    all_states.append(env.reset())\n",
    "    done = False\n",
    "    while not done:\n",
    "        s,r,done,_ = env.step(env.action_space.sample())\n",
    "        all_states.append(s)\n",
    "        if done:break\n",
    "            \n",
    "all_states = np.array(all_states)\n",
    "\n",
    "for obs_i in range(env.observation_space.shape[0]):\n",
    "    \n",
    "    plt.hist(all_states[:,obs_i],bins=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarize environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.core import ObservationWrapper\n",
    "class Binarizer(ObservationWrapper):\n",
    "    \n",
    "    def _observation(self,state):    \n",
    "        \n",
    "        #state = <round state to some amount digits.>\n",
    "        #hint: you can do that with round(x,n_digits)\n",
    "        #you will need to pick a different n_digits for each dimension\n",
    "\n",
    "        return tuple(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Binarizer(gym.make(\"CartPole-v0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = []\n",
    "for _ in range(1000):\n",
    "    all_states.append(env.reset())\n",
    "    done = False\n",
    "    while not done:\n",
    "        s,r,done,_ = env.step(env.action_space.sample())\n",
    "        all_states.append(s)\n",
    "        if done:break\n",
    "            \n",
    "all_states = np.array(all_states)\n",
    "\n",
    "for obs_i in range(env.observation_space.shape[0]):\n",
    "    \n",
    "    plt.hist(all_states[:,obs_i],bins=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from qlearning import QLearningAgent\n",
    "agent = QLearningAgent(alpha=0.5,epsilon=0.25,discount=0.99,\n",
    "                       getLegalActions = lambda s: range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "for i in range(1000):\n",
    "    rewards.append(play_and_train(env,agent))    \n",
    "    if i %100 ==0:\n",
    "        clear_output(True)\n",
    "        print \"mean reward\",np.mean(rewards[-100:])\n",
    "        plt.plot(rewards)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "## 4. Expected value SARSA (2 pts)\n",
    "\n",
    "```<go to expected_value_sarsa.py and implement missing lines in getValue(state)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make(\"Taxi-v2\")\n",
    "\n",
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from expected_value_sarsa import EVSarsaAgent\n",
    "agent = EVSarsaAgent(alpha=0.5,epsilon=0.25,discount=0.99,\n",
    "                       getLegalActions = lambda s: range(n_actions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train EV-SARSA\n",
    "\n",
    "Note that it uses __the same update parameters as__ qlearning so you can use the ```play_and_train``` function from q-learning.\n",
    "\n",
    "Please try both constant epsilon = 0.25 and decreasing epsilon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 EV-sarsa on CartPole\n",
    "\n",
    "Now train the `EVSarsaAgent` on CartPole-v0 env with binarizer you used above for Q-learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = <make env and wrap it with binarizer>\n",
    "\n",
    "agent = <your code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<train me>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Massive experiments\n",
    "\n",
    "This is the final part of the homework. You can pick any of the 3 tasks listed below. Or take more that one and get score for each of them independently.\n",
    "\n",
    "_If you feel to cool for this kind of school, see bonus section below - it awwards just as much points_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Algorithm comparison (4 points)\n",
    "\n",
    "\n",
    "For this experiment, you will need to write the code to answer to compare algorithm performance and produce plots/tables with experimental results that can be used to compare them.\n",
    "\n",
    "Take CartPole or Taxi and compare learning performance of all 3 algorithms under those conditions:\n",
    "\n",
    "* Constant epsilon 0.25, 0.1 and 0.001\n",
    "* Decreasing epsilong starting from 0.25 (decrease any way you want)\n",
    "* It's probably a good idea to plot learning curves (reward / games played)\n",
    "* At the end of your assignment, please describe in which conditions does each algorithm work better (if at all).\n",
    "\n",
    "* It's also useful to double-check if experiment results are robust to re-running and if they aren't - average over several runs.\n",
    "* If you use CartPole-v0, use same binarization techniques.\n",
    "\n",
    "It is __highly recommended__ that your code automatically builds the plot or prints the table.\n",
    "\n",
    "A creative approach to visualization or trying out more ideas will be awwarded with bonus points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus I: Advanced algorithms (4+ points)\n",
    "\n",
    "Implement any of the three algorithms:\n",
    "* n-step expected value SARSA or Q-learning\n",
    "* EV-SARSA or Q-learning( using eligibility traces aka TD(lambda)\n",
    "* q-learning with experience replay\n",
    "\n",
    "_(you will likely need to create a new file for that, just like qlearning.py)_\n",
    "\n",
    "* Show that this algorithm works no worse than those we already implemented for simple problems. \n",
    "* Try to find a way to learn faster than with default q-learning.\n",
    "\n",
    "You will also get +2 points for each algorithm implemented after the first one and any other awesomeness you're up to.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus II: Binarization techniques (4+ points total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure how learning performance depends on binarization and try some advanced binarizations.\n",
    "\n",
    "On CartPole-v0,\n",
    "* Measure learning speed and final performance against changing the amount of bins (uniformly across all dimensions) __(1 point)__\n",
    "* Try pre-processing observation with PCA, SparseCoding or any dimensionality reduction method you want, see what happens __(1 point)__\n",
    "\n",
    "* Apply binarization to solve MountainCar-v0 or LunarLander-v2 __(+2 points each)__\n",
    "\n",
    "_Warning, Mountaincar-v0 and LunarLander-v2 may train for ~hour. The only sanity check is that the frequency of successes more or less increases._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus II+\n",
    "\n",
    "Try applying categorical deep autoencoder as a binarization technique.\n",
    "\n",
    "Use gumbel-softmax, \n",
    "* Explaination and [tutorial](http://blog.evjang.com/2016/11/tutorial-categorical-variational.html), \n",
    "* [Example in lasagne](https://gist.github.com/justheuristic/fd08c15dee26dbe95d3e3a17855f3f7a/)\n",
    "\n",
    "* If you make it work on Cartpole, it's +5. \n",
    "* If on LunarLander or MountainCar, it's +5 more.\n",
    "* If it somehow ends up good on Atari (see week1 homework) or BipedalWalker-v2 or anything serious, it's a full project ( more pts :) )\n",
    "* If you have any questions or need any help, feel free to ask us!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
